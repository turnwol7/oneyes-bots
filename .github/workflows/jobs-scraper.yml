name: Job Scraper Cron

# Add permissions at the top level
permissions:
  contents: write  # This gives permission to write to the repository

on:
  schedule:
    - cron: '*/15 * * * *' 
  # Add manual trigger
  workflow_dispatch:  # This enables manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    timeout-minutes: 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Clean npm cache
        run: npm cache clean --force


      - name: Install dependencies
        run: npm install

      - name: Run job scraper
        run: node jobs_scraper.js
        env:
          JOBS_WEBHOOK_URL: ${{ secrets.JOBS_WEBHOOK_URL }}

      - name: Run NS jobs scraper
        run: node ns-jobs-scraper.js
        env:
          NS_JOBS_WEBHOOK_URL: ${{ secrets.NS_JOBS_WEBHOOK_URL }}

      # Add these new steps to commit changes
      - name: Configure Git
        run: |
          git config --global user.name '${{ secrets.GIT_USER_NAME }}'
          git config --global user.email '${{ secrets.GIT_USER_EMAIL }}'

      - name: Commit and push if changed
        run: |
          # Add both files
          git add jobs.json NS-jobs.json package-lock.json
          # Check if there are changes and commit them
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update jobs and dependencies" && git push)
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
